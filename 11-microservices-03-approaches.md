# Домашнее задание к занятию «Микросервисы: подходы»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

---
Мой выбор- GitLab
Когда речь идет об облачной системе, это означает, что вся инфраструктура и ресурсы, необходимые для выполнения системы или приложения, размещаются и управляются в облаке. Обычно облачные системы предоставляют гибкость и масштабируемость, поскольку они позволяют пользователям использовать только те ресурсы, которые им нужны, и масштабировать их по мере необходимости.

Система контроля версий Git является распределенной системой управления версиями, которая позволяет отслеживать изменения в исходном коде и сотрудничать с другими разработчиками. Git предоставляет возможность создавать различные ветки, коммитить изменения и объединять ветки. Это полезно при работе в команде, поскольку каждый разработчик может работать над своей собственной веткой и затем объединять изменения с основной веткой.

В GitLab каждый сервис может иметь свой собственный репозиторий, что позволяет отслеживать изменения и управлять кодом отдельно для каждого сервиса. Это удобно, поскольку позволяет организовать код в более модульную структуру и упростить разработку и развертывание.

GitLab CI/CD позволяет запускать сборки автоматически по событию из системы контроля версий Git. Это означает, что при каждом изменении в коде проекте будет запускаться процесс сборки и тестирования, чтобы проверить, что все работает правильно. Это помогает выявлять проблемы на ранних стадиях и предотвращает возможные ошибки.

Кроме того, GitLab CI/CD также позволяет запускать сборку по кнопке с указанием параметров. Это может быть полезно, когда хотим  запустить сборку с определенными настройками или параметрами, например, для тестирования определенной функции или конфигурации.

GitLab CI/CD предоставляет возможность привязать настройки к каждой сборке. Это означает, что можем определить различные настройки и параметры для каждой сборки, что дает нам большую гибкость и контроль над процессом сборки.

Также в GitLab CI/CD есть возможность создания шаблонов для различных конфигураций сборок. Это удобно, когда у нас есть несколько конфигураций, которые следует использовать для разных проектов или сервисов. Заместо повторного определения всех настроек и шагов каждый раз, вы можете создать шаблон и использовать его в разных проектах.

Важной особенностью GitLab CI/CD является возможность безопасного хранения секретных данных, таких как пароли, ключи доступа и другие конфиденциальные данные. Мы можем использовать встроенные инструменты GitLab для хранения этих данных и передачи их в защищенном виде во время процесса сборки.

GitLab CI/CD также поддерживает несколько конфигураций для сборки из одного репозитория. Это полезно, когда вам нужно собрать и развернуть проект в различных средах, например

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

---
Для обеспечения сбора и анализа логов в микросервисной архитектуре я предлагаю использовать Elastic Stack (ранее известный как ELK Stack), состоящий из следующих программных продуктов:

1. Elasticsearch: Центральное хранилище логов. Elasticsearch - это распределенный поисковый и аналитический движок, способный обработать большие объемы данных и обеспечить масштабируемость для хранения и поиска логов. Он обеспечивает высокую производительность и эффективность при поиске, индексации и агрегации логов.

2. Logstash: Инструмент сбора и обработки логов. Logstash предназначен для сбора, фильтрации, преобразования и отправки логов в Elasticsearch. Он может принимать логи из различных источников (включая stdout) и обрабатывать их для нормализации формата или извлечения полезной информации.

3. Kibana: Интерфейс пользователя для визуализации и анализа логов. Kibana предоставляет централизованный пользовательский интерфейс, который позволяет разработчикам и администраторам выполнять поиск, фильтрацию, визуализацию и анализ логов, используя мощные возможности поиска и агрегации данных Elasticsearch. Кроме того, Kibana также предоставляет возможность сохранения и обмена ссылками на запросы и визуализации логов.

Данное решение соответствует всем требованиям:

- Сбор логов в центральное хранилище: Logstash может быть настроен для сбора логов со всех хостов, обслуживающих систему. Он может принимать логи из различных источников, включая stdout приложений, и отправлять их в Elasticsearch для хранения.

- Минимальные требования к приложениям: Важным преимуществом Elastic Stack является возможность сбора логов из stdout приложений без необходимости внесения изменений в код приложений. При отправке логов в stdout, Logstash может перехватывать их и обрабатывать дальше.

- Гарантированная доставка логов: Elasticsearch обеспечивает надежную и масштабируемую хранение логов. Он реплицирует данные и обеспечивает отказоустойчивость, что гарантирует сохранность логов даже в случае сбоев.

- Обеспечение поиска и фильтрации: Elasticsearch предоставляет мощные возможности поиска и фильтрации данных. Вы можете выполнять сложные запросы с использованием запросов на основе текста, фильтров по полю, агрегаций и других функций Elasticsearch для нахождения нужных записей логов.

- Пользовательский интерфейс для разработчиков: Kibana предоставляет интуитивно понятный пользовательский интерфейс для визуализации и анализа логов. Разработчики могут использовать его для выполнения поиска, фильтрации и анализа логов, а также получения полезной информации из данных логов.

- Возможность сохранения ссылок на поиск: Kibana позволяет сохранять запросы и визуализации логов в виде дашбордов и предоставлять ссылки на них. Это позволяет обмениваться ссылками на сохраненные запросы и визуализации, чтобы другие разработчики могли легко повторно использовать или изучать интересующие запросы.

Еlastic Stack является широко используемым и открытым решением для сбора и анализа логов. Он имеет большое сообщество пользователей и разработчиков, что обеспечивает доступ к обширной документации, сообществу поддержки и возможности для расширения и настройки под конкретные потребности.
## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

---
Для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре я предлагаю использовать Prometheus и Grafana.

1. Prometheus: Prometheus - это система мониторинга и оповещения с открытым исходным кодом, которая специально разработана для сбора и хранения метрик. Она предоставляет гибкие возможности для мониторинга и сбора метрик со всех хостов, обслуживающих систему. Prometheus позволяет собирать метрики состояния ресурсов хостов (такие как CPU, RAM, HDD, Network) и метрики, специфичные для каждого сервиса в виде временных рядов.

2. Grafana: Grafana - это визуализационная платформа с открытым исходным кодом, которая предоставляет пользовательский интерфейс для отображения метрик, построения графиков и создания дашбордов. Grafana работает с различными источниками данных, включая Prometheus. Он позволяет настраивать различные панели для отслеживания состояния системы, делать запросы и агрегировать информацию из собранных метрик.

Данное решение соответствует всем требованиям:

- Сбор метрик со всех хостов: Prometheus предоставляет возможность сбора метрик из различных источников, что позволяет собирать данные с каждого хоста.

- Сбор метрик состояния ресурсов хостов и сервисов: Prometheus позволяет собирать метрики состояния ресурсов хостов (такие как CPU, RAM, HDD, Network) и метрики, специфичные для каждого сервиса. Это позволяет отслеживать использование ресурсов и производительность каждого хоста и сервиса.

- Пользовательский интерфейс для запросов и агрегирования информации: Grafana предоставляет понятный и гибкий пользовательский интерфейс, который позволяет делать запросы к данным, фильтровать и агрегировать информацию, а также создавать графики и дашборды для визуализации состояния системы.

- Пользовательский интерфейс для настройки панелей: Grafana позволяет настраивать различные панели для отслеживания состояния системы. Вы можете создавать панели с необходимыми графиками и метриками, а также настраивать оповещения и уведомления.

Prometheus и Grafana являются популярными инструментами для мониторинга и визуализации метрик. Они имеют простую установку и настройку, а также активное сообщество пользователей и разработчиков. Благодаря этому, вы сможете легко найти поддержку, документацию и расширения для адаптации решения под ваши специфические требования.

Кроме того, Prometheus и Grafana также имеют возможность интеграции с другими инструментами мониторинга и оповещения, такими как Alertmanager, для получения информации о событиях и отправки уведомлений. Это обеспечивает комплексное решение для мониторинга и анализа состояния хостов и сервисов в микросервисной архитектуре.

## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
